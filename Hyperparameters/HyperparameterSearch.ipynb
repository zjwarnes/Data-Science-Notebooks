{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.4 64-bit ('thesis': conda)"
  },
  "interpreter": {
   "hash": "cad2c7d5e3bc58b6b6c0b5aa85ab8e4719e85247c9468e0fa3d3af884c83458f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import uniform, geom, loguniform, randint, expon\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline as Pipeline\n",
    "from sklearn.datasets import load_iris, load_boston, load_diabetes, load_digits, load_linnerud, load_wine, load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.1\n",
    "RANDOM_STATE = 10\n",
    "\n",
    "data = load_breast_cancer()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "\n",
    "X = df.drop(['target'], axis=1)\n",
    "y = df['target'].astype(float)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_JOBS = 1\n",
    "K_FOLDS = 10\n",
    "N_ITER_NO_CHANGE = 100\n",
    "SCORING_METRIC = 'roc_auc'\n",
    "\n",
    "# Gradient Boosting Parameters\n",
    "hyper_parameters = {\n",
    "        'model__n_estimators': [50, 150, 300],\n",
    "        'model__learning_rate': [0.1, 0.03, 0.001],\n",
    "        'model__max_depth': [3, 5, 8],\n",
    "        'model__max_features': ['sqrt'], \n",
    "        'model__min_samples_split': [2],\n",
    "        'model__n_iter_no_change': [N_ITER_NO_CHANGE], # Note single elements should still be in a list\n",
    "        'model__random_state': [RANDOM_STATE],\n",
    "        'model__min_samples_leaf': [2, 10]\n",
    "}\n",
    "\n",
    "# Make pipeline - Add steps if needed, i.e. feature selection\n",
    "pipe = Pipeline(steps=[\n",
    "    ('model', GradientBoostingClassifier())\n",
    "])\n",
    "\n",
    "# 'n_iter' no longer needed as all combinations are checked\n",
    "search_space = GridSearchCV(\n",
    "    pipe, hyper_parameters, \n",
    "    cv=K_FOLDS, scoring=SCORING_METRIC, n_jobs = N_JOBS, \n",
    "    return_train_score=True, verbose = 1\n",
    ")\n",
    "search_space.fit(X_train, y_train) \n",
    "\n",
    "y_pred = search_space.best_estimator_.predict(X_train)\n",
    "y_pred_prob = search_space.best_estimator_.predict_proba(X_train)[:,1]\n",
    "y_pred_test = search_space.best_estimator_.predict_proba(X_test)[:,1]\n",
    "\n",
    "print( \n",
    "    'Best Training Score: ', search_space.cv_results_['mean_train_score'][search_space.best_index_], \n",
    "    '\\nBest Test Score: ', search_space.best_score_,\n",
    "    '\\nHold Out Test Score: ', roc_auc_score(y_test, y_pred_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N_ITER = 54\n",
    "N_JOBS = 1\n",
    "K_FOLDS = 10\n",
    "N_ITER_NO_CHANGE = 100\n",
    "SCORING_METRIC = 'roc_auc'\n",
    "\n",
    "hyper_parameters = {\n",
    "        'model__n_estimators': randint(50,500),\n",
    "        'model__learning_rate': loguniform(3e-4, 3e-1),\n",
    "        'model__max_depth': randint(3,10),\n",
    "        'model__max_features': ['sqrt'], \n",
    "        'model__min_samples_split': randint(2,20),\n",
    "        'model__n_iter_no_change': [N_ITER_NO_CHANGE], # Note single elements should still be in a list\n",
    "        'model__random_state': [RANDOM_STATE],\n",
    "        'model__min_samples_leaf': randint(1,10)\n",
    "}\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    ('model', GradientBoostingClassifier())\n",
    "])\n",
    "\n",
    "search_space = RandomizedSearchCV(\n",
    "    pipe, hyper_parameters, \n",
    "    n_iter = N_ITER, cv=K_FOLDS, \n",
    "    scoring=SCORING_METRIC, n_jobs = N_JOBS, \n",
    "    return_train_score=True, verbose = 1\n",
    ")\n",
    "search_space.fit(X_train, y_train) \n",
    "\n",
    "y_pred = search_space.best_estimator_.predict(X_train)\n",
    "y_pred_prob = search_space.best_estimator_.predict_proba(X_train)[:,1]\n",
    "y_pred_test = search_space.best_estimator_.predict_proba(X_test)[:,1]\n",
    "\n",
    "print( \n",
    "    'Best Training Score: ', search_space.cv_results_['mean_train_score'][search_space.best_index_], \n",
    "    '\\nBest Test Score: ', search_space.best_score_,\n",
    "    '\\nHold Out Test Score: ', roc_auc_score(y_test, y_pred_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "N_ITER = 54\n",
    "N_JOBS = 1\n",
    "hyper_parameters = {\n",
    "        'n_estimators': Integer(50, 300),\n",
    "        'max_depth': Integer(3, 10),\n",
    "        'min_samples_split': Integer(2, 300),\n",
    "        'learning_rate': Real(3e-6, 3e-1,prior='log-uniform'),     \n",
    "        'max_features': Categorical(['sqrt', None]),\n",
    "}\n",
    "search_space = BayesSearchCV(\n",
    "    estimator=GradientBoostingClassifier(\n",
    "        n_iter_no_change=N_ITER_NO_CHANGE, \n",
    "        random_state=RANDOM_STATE\n",
    "    ),\n",
    "    search_spaces=hyper_parameters,\n",
    "    scoring=SCORING_METRIC,\n",
    "    cv=K_FOLDS,\n",
    "    n_iter=N_ITER,\n",
    "    random_state=RANDOM_STATE,\n",
    "    return_train_score=True,\n",
    "    verbose = 1,\n",
    "    n_jobs=N_JOBS\n",
    ")\n",
    "# executes bayesian optimization\n",
    "_ = search_space.fit(X_train, y_train)\n",
    "\n",
    "y_pred = search_space.best_estimator_.predict(X_train)\n",
    "y_pred_prob = search_space.best_estimator_.predict_proba(X_train)[:,1]\n",
    "y_pred_test = search_space.best_estimator_.predict_proba(X_test)[:,1]\n",
    "\n",
    "# model can be saved, used for predictions or scoring\n",
    "print( \n",
    "    'Best Training Score: ', search_space.cv_results_['mean_train_score'][search_space.best_index_], \n",
    "    '\\nBest Test Score: ', search_space.best_score_,\n",
    "    '\\nHold Out Test Score: ', roc_auc_score(y_test, y_pred_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from skopt.plots import plot_objective, plot_histogram\n",
    "\n",
    "_ = plot_objective(search_space.optimizer_results_[0],\n",
    "                   n_minimum_search=int(1e8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}